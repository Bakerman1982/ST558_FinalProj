[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Diabetes Health Indicators - Modeling",
    "section": "",
    "text": "library(tidyverse)\nlibrary(dplyr)\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(randomForest)\n\n\nDiabetes Health Indicators Modeling\nAfter conducting an exploratory data analysis (EDA), our next objective is for inference about this dataset and to posit several models, test them, and determine which ones best describe our data. Key variables of interest include high cholesterol, high blood pressure, general health and age. Utilizing logistic regression modeling, classification tree modeling, and random forest modeling; we will identify the best-performing model from each category and compare their performance on the test data to determine the overall best model.\n\n#Read in the dataset, Factorize the binary variables for better downstream analysis and remove BMI observations 50.  Combining in this way saves substantial amount of memory in the R environment. \ndiabetes_data_clean &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\") %&gt;%\n  mutate_at(vars(Diabetes_binary, HighBP, HighChol, CholCheck, Smoker, \n                 Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, \n                 Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, \n                 DiffWalk, Sex), as.factor) %&gt;%\n  filter(BMI &lt; 50)\n\n\n\nData Preparation for Modeling\nUsing the caret package syntax, I have split the data into train and test at a 70:30 ratio respectively. This is done as a mean of testing our predictions on testing, or unseen data. This acts as a baseline to which we can refer back to and gauge model performance.\n\n#Split the data using caret package syntax\nset.seed(13579)\ndiabetesIndex &lt;- createDataPartition(diabetes_data_clean$Diabetes_binary, p = 0.7, list = FALSE)\ndiabetes_train &lt;- diabetes_data_clean[diabetesIndex, ] #Count = 175,794\ndiabetes_test &lt;- diabetes_data_clean[-diabetesIndex, ] #Count = 75,339\n\n#I had some problems downstream while planning and executing code to build models. R does not like when I run train() on a response variable with strictly numeric factors.  The following code corrects that issue by changing the response values from \"0\" and \"1\" to \"X0\" and \"X1\".  Henceforth, \"X0\" will indicate patients who do not have a diabetes diagnosis while an \"X1\" will affirm a diabetes diagnosis. \n\n# Rename levels to valid variable names\nlevels(diabetes_train$Diabetes_binary) &lt;- make.names(levels(diabetes_train$Diabetes_binary))\nlevels(diabetes_test$Diabetes_binary) &lt;- make.names(levels(diabetes_test$Diabetes_binary))\n\n\n\nLogistic Regression Modeling and Log Loss\nA Logistic Regression Model is a modeling technique designed for binary classification, where the target variable is categorical with two possible outcomes (e.g., 0 and 1, true and false, or success and failure). This model estimates the likelihood that a particular input falls into one of the categories. Logistic Regression is a great option for modeling with this specific dataset since we are working in binary data while we also want to makes no assumptions about the distribution of our data. Another strength is that LogLoss compares prediction probabilities to binary output; and evaluates probability estimates which make for a more robust measurement method over accuracy for probabilistic models. Interpretation is made simpler with log-odd to one-unit change predictor variable.\nUsing linear modeling might not be appropriate for this data. Logistic regression modeling would be a better alternative. In the plot below, notice that the linear regression line does not fit our data well for a variable BMI. The entire linear regression line completely avoids the positive diabetes diagnosis points. This is due to the overwhelmingly disproportion of non-diabetic responses.\n\nggplot(diabetes_data_clean, aes(x = BMI, y = Diabetes_binary)) + \n  geom_jitter() + \n  geom_smooth(method = \"lm\", aes(group = 1))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nCaret contains a trainControl() function that allows the setting of modeling parameters\n\n# Define the control using a 5-fold cross-validation\ntrain_control &lt;- trainControl(method = \"cv\", number = 5, summaryFunction = mnLogLoss, classProbs = TRUE)\n#NOTES:  classProbs has to be TRUE for mnLogLoss to work.\n#Source:  https://stackoverflow.com/questions/59669490/error-with-caret-and-summaryfunction-mnlogloss-columns-consistent-with-lev\n\nHere is the setup for performing a logistic regression modeling on three candidate models I am interested in testing. These same formula models will be used in classification and in random forest modeling.\n\n# Model 1: LogReg Model with all except GenHlth and Age\nset.seed(13579)\nmodel_1_LogReg &lt;- train(Diabetes_binary ~ . -GenHlth -Age, \n                data = diabetes_train, \n                method = \"glm\", \n                family = binomial, \n                trControl = train_control, \n                metric = \"logLoss\")\n\n# Model 2: LogReg Model with all except HighBP and HighChol\nset.seed(13579)\nmodel_2_LogReg &lt;- train(Diabetes_binary ~ . -HighBP -HighChol, \n                data = diabetes_train, \n                method = \"glm\", \n                family = binomial, \n                trControl = train_control, \n                metric = \"logLoss\")\n\n# Model 3: LogReg Model with all except HighChol\nset.seed(13579)\nmodel_3_LogReg &lt;- train(Diabetes_binary ~ . -HighChol, \n                data = diabetes_train, \n                method = \"glm\", \n                family = binomial, \n                trControl = train_control, \n                metric = \"logLoss\")\n\n\n# Create a data frame to store the log-loss values\nlog_loss_results &lt;- data.frame(\n  Model = c(\"Model 1\", \"Model 2\", \"Model 3\"),\n  LogLoss = c(\n    min(model_1_LogReg$results$logLoss),\n    min(model_2_LogReg$results$logLoss),\n    min(model_3_LogReg$results$logLoss)\n  )\n)\n\n# Print the log-loss results.\n# Lower Log Loss indicates better model performance in that lower log loss can be interpreted as less of a difference between the actual classes and those that were predicted.\nprint(log_loss_results)\n\n    Model   LogLoss\n1 Model 1 0.3286191\n2 Model 2 0.3252869\n3 Model 3 0.3190218\n\n\n\n\nClassification Tree\nA classification tree model, commonly referred to as a decision tree, is a predictive technique used for classification problems. It operates by dividing the dataset into smaller subsets based on the values of input features, creating a tree-like structure. In this structure, each internal node signifies a decision based on a particular feature, each branch indicates the result of that decision, and each leaf node denotes a class label. Binary data works well with tree data since trees are naturally forked in halves. This is visually intuitive in that it tells the story of the decision at the node. Although we handled outliers earlier, trees are less sensitive to them. Like logistic regression, classification trees make no assumptions about the distribution–linearity is not consequential to this model.\n\nset.seed(13579)\n\n# Model 1: LogReg Model with all except GenHlth and Age\ncp_values_model_1 &lt;- seq(0.000, 0.004, by = 0.001)\nresults_model_1 &lt;- data.frame(CP = numeric(), Accuracy = numeric())\n\n# Loop through each cp value\nfor (cp in cp_values_model_1) {\n  model_1_tree &lt;- rpart(Diabetes_binary ~ . -GenHlth -Age, data = diabetes_train, method = \"class\", control = rpart.control(minbucket = 20, cp = cp))\n  \n  # Predict on the test set\n  model_1_predictions &lt;- predict(model_1_tree, diabetes_test, type = \"class\")\n  \n  # Confusion matrix to evaluate the model\n  model_1_conf_matrix &lt;- confusionMatrix(model_1_predictions, diabetes_test$Diabetes_binary)\n  \n  # Store accuracy\n  accuracy &lt;- model_1_conf_matrix$overall['Accuracy']\n  results_model_1 &lt;- rbind(results_model_1, data.frame(CP = cp, Accuracy = accuracy))\n}\n\n# Find the best cp based on maximum accuracy\nbest_cp_model_1 &lt;- results_model_1$CP[which.max(results_model_1$Accuracy)]\nprint(paste0(\"Optimal Complexity Parameter: \", best_cp_model_1))\n\n[1] \"Optimal Complexity Parameter: 0.001\"\n\n# Fit the final model using the best cp value\nmodel_1_final_tree &lt;- rpart(Diabetes_binary ~ . -GenHlth -Age, data = diabetes_train, method = \"class\", control = rpart.control(minbucket = 20, cp = best_cp_model_1))\n\n# Plot the tree\npar(mar = c(1, 1, 1, 1))  # Adjust margins (bottom, left, top, right)\nmodel_1_rpart_plot &lt;- rpart.plot(model_1_final_tree, type = 2, extra = 104, fallen.leaves = TRUE, main = \"Classification Tree for Diabetes Data Model 1\")\n\n\n\n\n\n\n\n# Print the final confusion matrix for the best model\nmodel_1_final_predictions &lt;- predict(model_1_final_tree, diabetes_test, type = \"class\")\nmodel_1_final_conf_matrix &lt;- confusionMatrix(model_1_final_predictions, diabetes_test$Diabetes_binary)\nprint(model_1_final_conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    X0    X1\n        X0 64471  9603\n        X1   520   745\n                                          \n               Accuracy : 0.8656          \n                 95% CI : (0.8632, 0.8681)\n    No Information Rate : 0.8626          \n    P-Value [Acc &gt; NIR] : 0.008606        \n                                          \n                  Kappa : 0.1014          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.99200         \n            Specificity : 0.07199         \n         Pos Pred Value : 0.87036         \n         Neg Pred Value : 0.58893         \n             Prevalence : 0.86265         \n         Detection Rate : 0.85575         \n   Detection Prevalence : 0.98321         \n      Balanced Accuracy : 0.53200         \n                                          \n       'Positive' Class : X0              \n                                          \n\n\n\nset.seed(13579)\n\n# Model 2: LogReg Model with all except HighBP and HighChol\ncp_values_model_2 &lt;- seq(0.000, 0.004, by = 0.001)\nresults_model_2 &lt;- data.frame(CP = numeric(), Accuracy = numeric())\n\n# Loop through each cp value\nfor (cp in cp_values_model_2) {\n  model_2_tree &lt;- rpart(Diabetes_binary ~ . -HighBP -HighChol, data = diabetes_train, method = \"class\", control = rpart.control(minbucket = 20, cp = cp))\n  \n  # Predict on the test set\n  model_2_predictions &lt;- predict(model_2_tree, diabetes_test, type = \"class\")\n  \n  # Confusion matrix to evaluate the model\n  model_2_conf_matrix &lt;- confusionMatrix(model_2_predictions, diabetes_test$Diabetes_binary)\n  \n  # Store accuracy\n  accuracy &lt;- model_2_conf_matrix$overall['Accuracy']\n  results_model_2 &lt;- rbind(results_model_2, data.frame(CP = cp, Accuracy = accuracy))\n}\n\n# Find the best cp based on maximum accuracy\nbest_cp_model_2 &lt;- results_model_2$CP[which.max(results_model_2$Accuracy)]\nprint(paste0(\"Optimal Complexity Parameter: \", best_cp_model_2))\n\n[1] \"Optimal Complexity Parameter: 0.001\"\n\n# Fit the final model using the best cp value\nmodel_2_final_tree &lt;- rpart(Diabetes_binary ~ . -HighBP -HighChol, data = diabetes_train, method = \"class\", control = rpart.control(minbucket = 20, cp = best_cp_model_2))\n\n# Plot the tree\npar(mar = c(1, 1, 1, 1))  # Adjust margins (bottom, left, top, right)\nmodel_2_rpart_plot &lt;- rpart.plot(model_2_final_tree, type = 2, extra = 104, fallen.leaves = TRUE, main = \"Classification Tree for Diabetes Data Model 2\")\n\n\n\n\n\n\n\n# Print the final confusion matrix for the best model\nmodel_2_final_predictions &lt;- predict(model_2_final_tree, diabetes_test, type = \"class\")\nmodel_2_final_conf_matrix &lt;- confusionMatrix(model_2_final_predictions, diabetes_test$Diabetes_binary)\nprint(model_2_final_conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    X0    X1\n        X0 64434  9586\n        X1   557   762\n                                          \n               Accuracy : 0.8654          \n                 95% CI : (0.8629, 0.8678)\n    No Information Rate : 0.8626          \n    P-Value [Acc &gt; NIR] : 0.01503         \n                                          \n                  Kappa : 0.1028          \n                                          \n Mcnemar's Test P-Value : &lt; 2e-16         \n                                          \n            Sensitivity : 0.99143         \n            Specificity : 0.07364         \n         Pos Pred Value : 0.87049         \n         Neg Pred Value : 0.57771         \n             Prevalence : 0.86265         \n         Detection Rate : 0.85525         \n   Detection Prevalence : 0.98249         \n      Balanced Accuracy : 0.53253         \n                                          \n       'Positive' Class : X0              \n                                          \n\n\n\nset.seed(13579)\n\n# Model 3: LogReg Model with all except HighChol\ncp_values_model_3 &lt;- seq(0.000, 0.004, by = 0.001)\nresults_model_3 &lt;- data.frame(CP = numeric(), Accuracy = numeric())\n\n# Loop through each cp value\nfor (cp in cp_values_model_3) {\n  model_3_tree &lt;- rpart(Diabetes_binary ~ . -HighChol, data = diabetes_train, method = \"class\", control = rpart.control(minbucket = 20, cp = cp))\n  \n  # Predict on the test set\n  model_3_predictions &lt;- predict(model_3_tree, diabetes_test, type = \"class\")\n  \n  # Confusion matrix to evaluate the model\n  model_3_conf_matrix &lt;- confusionMatrix(model_3_predictions, diabetes_test$Diabetes_binary)\n  \n  # Store accuracy\n  accuracy &lt;- model_3_conf_matrix$overall['Accuracy']\n  results_model_3 &lt;- rbind(results_model_3, data.frame(CP = cp, Accuracy = accuracy))\n}\n\n# Find the best cp based on maximum accuracy\nbest_cp_model_3 &lt;- results_model_3$CP[which.max(results_model_3$Accuracy)]\nprint(paste0(\"Optimal Complexity Parameter: \", best_cp_model_3))\n\n[1] \"Optimal Complexity Parameter: 0.002\"\n\n# Fit the final model using the best cp value\nmodel_3_final_tree &lt;- rpart(Diabetes_binary ~ . -HighChol, data = diabetes_train, method = \"class\", control = rpart.control(minbucket = 20, cp = best_cp_model_3))\n\n# Plot the tree\npar(mar = c(1, 1, 1, 1))  # Adjust margins (bottom, left, top, right)\nmodel_3_rpart_plot &lt;- rpart.plot(model_3_final_tree, type = 2, extra = 104, fallen.leaves = TRUE, main = \"Classification Tree for Diabetes Data Model 3\")\n\n\n\n\n\n\n\n# Print the final confusion matrix for the best model\nmodel_3_final_predictions &lt;- predict(model_3_final_tree, diabetes_test, type = \"class\")\nmodel_3_final_conf_matrix &lt;- confusionMatrix(model_3_final_predictions, diabetes_test$Diabetes_binary)\nprint(model_3_final_conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    X0    X1\n        X0 64327  9380\n        X1   664   968\n                                          \n               Accuracy : 0.8667          \n                 95% CI : (0.8642, 0.8691)\n    No Information Rate : 0.8626          \n    P-Value [Acc &gt; NIR] : 0.0006312       \n                                          \n                  Kappa : 0.129           \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.98978         \n            Specificity : 0.09354         \n         Pos Pred Value : 0.87274         \n         Neg Pred Value : 0.59314         \n             Prevalence : 0.86265         \n         Detection Rate : 0.85383         \n   Detection Prevalence : 0.97834         \n      Balanced Accuracy : 0.54166         \n                                          \n       'Positive' Class : X0              \n                                          \n\n\n\n# Function to calculate evaluation metrics from a confusion matrix\ncalculate_metrics &lt;- function(conf_matrix) {\n  accuracy &lt;- conf_matrix$overall['Accuracy']\n  precision &lt;- conf_matrix$byClass['Pos Pred Value']\n  recall &lt;- conf_matrix$byClass['Sensitivity']\n  f1 &lt;- 2 * ((precision * recall) / (precision + recall))\n  return(c(accuracy = accuracy, precision = precision, recall = recall, f1 = f1))\n}\n\n# Evaluate metrics for each model\nmodel_1_metrics &lt;- calculate_metrics(model_1_final_conf_matrix)\nmodel_2_metrics &lt;- calculate_metrics(model_2_final_conf_matrix)\nmodel_3_metrics &lt;- calculate_metrics(model_3_final_conf_matrix)\n\n# Combine metrics into a data frame for comparison\nmetrics_df &lt;- data.frame(\n  Model = c(\"Model_1\", \"Model_2\", \"Model_3\"),\n  Accuracy = c(model_1_metrics[\"accuracy.Accuracy\"], \n               model_2_metrics[\"accuracy.Accuracy\"], \n               model_3_metrics[\"accuracy.Accuracy\"]),\n  Precision = c(model_1_metrics[\"precision.Pos Pred Value\"], \n                model_2_metrics[\"precision.Pos Pred Value\"], \n                model_3_metrics[\"precision.Pos Pred Value\"]),\n  Recall = c(model_1_metrics[\"recall.Sensitivity\"], \n             model_2_metrics[\"recall.Sensitivity\"], \n             model_3_metrics[\"recall.Sensitivity\"]),\n  F1_Score = c(model_1_metrics[\"f1.Pos Pred Value\"], \n               model_2_metrics[\"f1.Pos Pred Value\"], \n               model_3_metrics[\"f1.Pos Pred Value\"])\n)\n\n# Identify the model names and metrics\nmodel_names &lt;- metrics_df$Model\nmetrics &lt;- metrics_df[, -1]  # Exclude the Model column\n\n# Find the maximum values and corresponding model names for each metric\nmax_accuracy_value &lt;- max(metrics$Accuracy, na.rm = TRUE)\nmax_accuracy_model &lt;- model_names[which.max(metrics$Accuracy)]\n\nmax_precision_value &lt;- max(metrics$Precision, na.rm = TRUE)\nmax_precision_model &lt;- model_names[which.max(metrics$Precision)]\n\nmax_recall_value &lt;- max(metrics$Recall, na.rm = TRUE)\nmax_recall_model &lt;- model_names[which.max(metrics$Recall)]\n\nmax_f1_value &lt;- max(metrics$F1_Score, na.rm = TRUE)\nmax_f1_model &lt;- model_names[which.max(metrics$F1_Score)]\n\n# Combine the results into a data frame\nmax_metrics_df &lt;- data.frame(\n  Metric = c(\"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"),\n  Model = c(max_accuracy_model, max_precision_model, max_recall_model, max_f1_model),\n  Max_Value = c(max_accuracy_value, max_precision_value, max_recall_value, max_f1_value)\n)\n\n# Print the resulting data frame\nprint(metrics_df)\n\n    Model  Accuracy Precision    Recall  F1_Score\n1 Model_1 0.8656340 0.8703594 0.9919989 0.9272067\n2 Model_2 0.8653685 0.8704945 0.9914296 0.9270346\n3 Model_3 0.8666826 0.8727394 0.9897832 0.9275837\n\n\n\n\nRandom Forest\nA random forest is a powerful machine learning technique that utilizes a collection of decision trees to enhance classification performance and minimize the risk of overfitting. In contrast to a single decision tree, which can be overly sensitive to variations in the training data, a random forest builds numerous decision trees by randomly selecting subsets of both the data and the features for each tree. Each tree independently generates its predictions, and the final classification is determined across all trees. This method increases the overall stability and accuracy of the model by reducing the likelihood of capturing noise that may exist in any single dataset.\n\nset.seed(13579)\n\n#Fit the randomForest models\nmodel_1_rf &lt;- randomForest(Diabetes_binary ~ . -GenHlth -Age, data = diabetes_train, mtry = ncol(diabetes_train) / 3, ntree = 50, importance = TRUE)\nmodel_2_rf &lt;- randomForest(Diabetes_binary ~ . -HighBP -HighChol, data = diabetes_train, mtry = ncol(diabetes_train) / 3, ntree = 50, importance = TRUE)\nmodel_3_rf &lt;- randomForest(Diabetes_binary ~ . -HighChol, data = diabetes_train, mtry = ncol(diabetes_train) / 3, ntree = 50, importance = TRUE)\n\n# Predict probabilities for the test set\nmodel_1_rfProbs &lt;- predict(model_1_rf, newdata = dplyr::select(diabetes_test, -Diabetes_binary), type = \"prob\")\nmodel_2_rfProbs &lt;- predict(model_2_rf, newdata = dplyr::select(diabetes_test, -Diabetes_binary), type = \"prob\")\nmodel_3_rfProbs &lt;- predict(model_3_rf, newdata = dplyr::select(diabetes_test, -Diabetes_binary), type = \"prob\")\n\n# Convert probabilities to predicted classes\n\nmodel_1_rfPred &lt;- ifelse(model_1_rfProbs[, 2] &gt; 0.5, \"X1\", \"X0\")\nmodel_2_rfPred &lt;- ifelse(model_2_rfProbs[, 2] &gt; 0.5, \"X1\", \"X0\")\nmodel_3_rfPred &lt;- ifelse(model_3_rfProbs[, 2] &gt; 0.5, \"X1\", \"X0\")\n\n# Create confusion matrices\nconf_matrix_1 &lt;- confusionMatrix(factor(model_1_rfPred, levels = levels(diabetes_test$Diabetes_binary)), diabetes_test$Diabetes_binary)\nconf_matrix_2 &lt;- confusionMatrix(factor(model_2_rfPred, levels = levels(diabetes_test$Diabetes_binary)), diabetes_test$Diabetes_binary)\nconf_matrix_3 &lt;- confusionMatrix(factor(model_3_rfPred, levels = levels(diabetes_test$Diabetes_binary)), diabetes_test$Diabetes_binary)\n\n# Extract accuracy\naccuracy_1 &lt;- conf_matrix_1$overall['Accuracy']\naccuracy_2 &lt;- conf_matrix_2$overall['Accuracy']\naccuracy_3 &lt;- conf_matrix_3$overall['Accuracy']\n\n# Create a dataframe with the accuracies\naccuracy_df &lt;- data.frame(\n  Model = c(\"Model 1\", \"Model 2\", \"Model 3\"),\n  Accuracy = c(accuracy_1, accuracy_2, accuracy_3)\n)\n\n# Print the dataframe\nprint(accuracy_df)\n\n    Model  Accuracy\n1 Model 1 0.8582142\n2 Model 2 0.8596079\n3 Model 3 0.8603114\n\n\n\n\nFinal Model Selection\nHere is a summary of the three different model outputs.\n\n# Print the logistic regression model results\nprint(log_loss_results)\n\n    Model   LogLoss\n1 Model 1 0.3286191\n2 Model 2 0.3252869\n3 Model 3 0.3190218\n\n\n\n# Print the classification model results\nprint(metrics_df)\n\n    Model  Accuracy Precision    Recall  F1_Score\n1 Model_1 0.8656340 0.8703594 0.9919989 0.9272067\n2 Model_2 0.8653685 0.8704945 0.9914296 0.9270346\n3 Model_3 0.8666826 0.8727394 0.9897832 0.9275837\n\n\n\n# Print the random forest model results\nprint(accuracy_df)\n\n    Model  Accuracy\n1 Model 1 0.8582142\n2 Model 2 0.8596079\n3 Model 3 0.8603114\n\n\nThe best model that fits the diabetes dataset best appears to be model 3, which excludes a high cholesterol main effect. Deciding factors were the lowest observable logloss, the highest accuracy in the random forest model and winner of three of the four metrics that measure classification models; accuracy, precision, and F1_Score. Model 3 was the least simplest compared to the other two models which had fewer main effects. I was somewhat surprised at this result.\nI had visited my primary care physician, Dr. Amanda Meeks, FNP, a few weeks before this project. In our discussion about my personal health, we had talked at length about how my blood pressure had crept upwards in the last check-in. My doctor mentioned that high blood pressure substantially increases the risk of having the other two conditions; as does having any one of the other medical conditions. The risks are so high that typically when diagnosed with either high blood pressure or high cholesterol, that initiates an automatic check for the other two conditions. With that in mind, I was expecting to see Model 1 perform better than it did with the inclusion of high cholesterol.\n\nAppendix: Variable description\n(Disease Control & Prevention, 2015)\nDiabetes_binary\nNOTE: The options present are different from the source data.\n0 = no diabetes/prediabetes\n1 = diabetes\n\nHighBP\n0 = no high BP\n1 = high BP\n\nHighChol\n0 = no high cholesterol\n1 = high cholesterol\n\nCholCheck\n0 = no cholesterol check in 5 years\n1 = cholesterol check in 5 years\n\nBMI\nContinuous Data\n\nSmoker\nTo the question: Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes]\n0 = no\n1 = yes\n\nStroke\nTo the question: (Ever told) you had a stroke.\n0 = no\n1 = yes\n\nHeartDiseaseorAttack\nCoronary heart disease (CHD) or myocardial infarction (MI)\n0 = no\n1 = yes\n\nPhysActivity\nPhysical activity in past 30 days (not including job)\n0 = no\n1 = yes\n\nFruits\nConsume Fruit 1 or more times per day\n0 = no\n1 = yes\n\nVeggies\nConsume Vegetables 1 or more times per day\n0 = no\n1 = yes\n\nHvyAlcoholConsump\n(adult men &gt;=14 drinks per week and adult women&gt;=7 drinks per week)\n0 = no\n1 = yes\n\nAnyHealthcare\nHave any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc.\n0 = no\n1 = yes\n\nNoDocbcCost\nTo the question: Was there a time in the past 12 months when you needed to see a doctor but could not because of cost?\n0 = no\n1 = yes\n\nGenHlth\nTo the question: Would you say that in general your health is: scale 1-5\n1 = excellent\n2 = very good\n3 = good\n4 = fair\n5 = poor\n\nMentHlth\nDays of poor mental health scale 1-30 days\n\nPhysHlth\nphysical illness or injury days in past 30 days scale 1-30\n\nDiffWalk\nDo you have serious difficulty walking or climbing stairs?\n0 = no\n1 = yes\n\nSex\n0 = female\n1 = male\n\nAge\nNOTE: The options present are different from the source data.\n1 = Age 18 to 24 Respondents with reported age between 18 and 24 years (18 &lt;= AGE &lt;= 24)\n2 = Age 25 to 29 Respondents with reported age between 25 and 29 years (25 &lt;= AGE &lt;= 29)\n3 = Age 30 to 34 Respondents with reported age between 30 and 34 years (30 &lt;= AGE &lt;= 34)\n4 = Age 35 to 39 Respondents with reported age between 35 and 39 years (35 &lt;= AGE &lt;= 39)\n5 = Age 40 to 44 Respondents with reported age between 40 and 44 years (40 &lt;= AGE &lt;= 44)\n6 = Age 45 to 49 Respondents with reported age between 45 and 49 years (45 &lt;= AGE &lt;= 49)\n7 = Age 50 to 54 Respondents with reported age between 50 and 54 years (50 &lt;= AGE &lt;= 54)\n8 = Age 55 to 59 Respondents with reported age between 55 and 59 years (55 &lt;= AGE &lt;= 59)\n9 = Age 60 to 64 Respondents with reported age between 60 and 64 years (60 &lt;= AGE &lt;= 64)\n10 = Age 65 to 69 Respondents with reported age between 65 and 69 years (65 &lt;= AGE &lt;= 69)\n11 = Age 70 to 74 Respondents with reported age between 70 and 74 years (70 &lt;= AGE &lt;= 74)\n12 = Age 75 to 79 Respondents with reported age between 75 and 79 years (75 &lt;= AGE &lt;= 79)\n13 = Age 80 or older Respondents with reported age between 80 and 99 years (80 &lt;= AGE &lt;= 99)\n\nEducation\nNOTE: The options present are different from the source data.\n1 = Never attended school or only kindergarten\n2 = Grades 1 through 8 (Elementary)\n3 = Grades 9 through 11 (Some high school)\n4 = Grade 12 or GED (High school graduate)\n5 = College 1 year to 3 years (Some college or technical school)\n6 = College 4 years or more (College graduate)\n\nIncome\nNOTE: The options present are different from the source data.\n1 = Less than $10,000\n2 = Less than $15,000 ($10,000 to less than $15,000)\n3 = Less than $20,000 ($15,000 to less than $20,000)\n4 = Less than $25,000 ($20,000 to less than $25,000)\n5 = Less than $35,000 ($25,000 to less than $35,000)\n6 = Less than $50,000 ($35,000 to less than $50,000)\n7 = Less than $75,000 ($50,000 to less than $75,000)\n8 = $75,000 or more\n\nLink to EDA.qmd on GitHub\n\n\n\n\n\n\n\n\n\nReferences\n\nDisease Control, C. for, & Prevention. (2015). BRFSS codebook 2015. https://www.cdc.gov/brfss/annual_data/2015/pdf/codebook15_llcp.pdf"
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Diabetes Health Indicators - Exploratory Data Analysis",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(outliers)\nlibrary(forcats)\nlibrary(gridExtra)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(patchwork)\n\n\nDiabetes Summary\nDiabetes is a common chronic disease in the United States, affecting millions of Americans and imposing a significant financial burden on the US healthcare system. It is a disease that impairs the body’s ability to regulate blood glucose, leading to severe complications like heart disease, vision loss, and kidney disease. Early diagnosis and management through lifestyle changes and medical treatments can lessen its impact. The Center for Disease Control (CDC) reports that as of 2018, 34.2 million Americans have diabetes, with substantial economic costs nearing $400 billion annually. To better understand diabetes, the CDC conducts an annual telephone survey through the Behavioral Risk Factor Surveillance System (BRFSS). They have been collecting observational data since 1984 and through this program, 400,000 responses are collected annually on various behaviors and conditions about the disease. In this exploratory data analysis, we will look at the variables, the factors, the problems that come with raw data. Visual help will give some insight into patterns and narratives.\n\n\nDataset and Variables\nThe dataset found in this analysis is from 2015. There are 253680 observations, 21 independent variables and a dependent variable called Diabetes_binary that indicates one of three categories relating to a diabetic diagnosis.\n\n#Read in the dataset\ndiabetes_data_raw &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\n\n#Listing of variables\ncolnames(diabetes_data_raw)\n\n [1] \"Diabetes_binary\"      \"HighBP\"               \"HighChol\"            \n [4] \"CholCheck\"            \"BMI\"                  \"Smoker\"              \n [7] \"Stroke\"               \"HeartDiseaseorAttack\" \"PhysActivity\"        \n[10] \"Fruits\"               \"Veggies\"              \"HvyAlcoholConsump\"   \n[13] \"AnyHealthcare\"        \"NoDocbcCost\"          \"GenHlth\"             \n[16] \"MentHlth\"             \"PhysHlth\"             \"DiffWalk\"            \n[19] \"Sex\"                  \"Age\"                  \"Education\"           \n[22] \"Income\"              \n\n\nUpon reviewing the dataset, I found no missing values. However, there are approximately 9,000 rows where the BMI values exceed 50. While I considered removing these extreme values, I decided against it for now. In a production setting, I would seek advice from a medical specialist or someone familiar with the data collection to investigate these high values for potential errors or explanations. I will conduct an outlier test on these values, and depending on the results, I may prepare two reports—one including the BMI extremes and one excluding them.\n\n#Checking for missing data\ndiabetes_data_NA_report &lt;- diabetes_data_raw %&gt;%\n  summarise_all(~sum(is.na(.))) %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Number of missing values discovered\")\nprint(diabetes_data_NA_report, n = Inf)\n\n# A tibble: 22 × 2\n   Variable             `Number of missing values discovered`\n   &lt;chr&gt;                                                &lt;int&gt;\n 1 Diabetes_binary                                          0\n 2 HighBP                                                   0\n 3 HighChol                                                 0\n 4 CholCheck                                                0\n 5 BMI                                                      0\n 6 Smoker                                                   0\n 7 Stroke                                                   0\n 8 HeartDiseaseorAttack                                     0\n 9 PhysActivity                                             0\n10 Fruits                                                   0\n11 Veggies                                                  0\n12 HvyAlcoholConsump                                        0\n13 AnyHealthcare                                            0\n14 NoDocbcCost                                              0\n15 GenHlth                                                  0\n16 MentHlth                                                 0\n17 PhysHlth                                                 0\n18 DiffWalk                                                 0\n19 Sex                                                      0\n20 Age                                                      0\n21 Education                                                0\n22 Income                                                   0\n\n\nAs part of wrangling the data, this code chunk was created to format the data into factors for variables that it makes sense to do so. The remaining factors I will leave as numeric values.\n\n#Factorize the binary variables for better downstream analysis. \ndiabetes_data_clean &lt;- diabetes_data_raw %&gt;%\n  mutate_at(vars(Diabetes_binary, HighBP, HighChol, CholCheck, Smoker, \n                 Stroke, HeartDiseaseorAttack, PhysActivity, Fruits, \n                 Veggies, HvyAlcoholConsump, AnyHealthcare, NoDocbcCost, \n                 DiffWalk, Sex), as.factor)\n\n\n\nOutlier Test for Variable BMI\nEarlier, I expressed concern about outliers in the BMI variable, and these concerns appear to be justified. Both numeric and visual tests indicate a substantial number of outliers. The numeric tests showed that 2,963 observations fell outside three standard deviations from the mean, while the IQR test identified 9,847 observations beyond the bounds.\n\n#Check outliers using Z-scores. \noutlier_z_data &lt;- diabetes_data_clean %&gt;%\n  mutate(z_score = (BMI - mean(BMI)) / sd(BMI)) %&gt;%\n  filter(abs(z_score) &gt; 3)       %&gt;%\n  arrange(BMI)\n\n#Check outliers using the interquartile method\nQ1 &lt;- quantile(diabetes_data_clean$BMI, 0.25)\nQ3 &lt;- quantile(diabetes_data_clean$BMI, 0.75)\nIQR &lt;- Q3 - Q1\noutlier_IQR_data &lt;- diabetes_data_clean %&gt;%\n  filter(BMI &lt; (Q1 - 1.5 * IQR) | BMI &gt; (Q3 + 1.5 * IQR))\n\n\ncount(outlier_z_data) # Number of outliers using the Z-Score method\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1  2963\n\nmin(outlier_z_data$BMI[outlier_z_data$BMI &gt;= 30]) # Finding cutoff value; lowest BMI value outside 3 SDs\n\n[1] 49\n\ncount(outlier_IQR_data) # Number of outliers using the IQR method\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1  9847\n\nmax(outlier_IQR_data$BMI[outlier_IQR_data$BMI &lt;= 30]) # Finding cutoff value; highest BMI outside of the lowerbound range\n\n[1] 13\n\nmin(outlier_IQR_data$BMI[outlier_IQR_data$BMI &gt;= 30]) # Finding cutoff value; lowest BMI outside of the upperbound range\n\n[1] 42\n\n\n\n#Remove BMI observations 50\ndiabetes_data_clean_noOutliers &lt;- diabetes_data_clean %&gt;%\n  filter(BMI &lt; 50)\n\nThis boxplot highlights in red observations that are considered outliers.\n\n\n# Combine the datasets\ncombined_data &lt;- bind_rows(\n  mutate(diabetes_data_clean, Source = \"With Outliers\"),\n  mutate(diabetes_data_clean_noOutliers, Source = \"No Outliers\")\n)\n\n# Plot with faceting\nggplot(combined_data, aes(x = \"\", y = BMI)) +\n  geom_boxplot(fill = \"lightblue\", color = \"black\", outlier.colour = \"red\") +\n  labs(title = \"Boxplot of BMI\", x = \"\", y = \"BMI\") +\n  facet_wrap(~ Source) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe histogram similarly illustrates the pronounced right skew caused by the outliers in the distribution. The dotted red lines indicate the boundaries for three standard deviations from the mean.\n\n\n# Combine the datasets\ncombined_data &lt;- bind_rows(\n  mutate(diabetes_data_clean, Source = \"With Outliers\"),\n  mutate(diabetes_data_clean_noOutliers, Source = \"No Outliers\")\n)\n\n# Calculate mean and standard deviation\nmean_bmi &lt;- mean(diabetes_data_clean$BMI, na.rm = TRUE)\nsd_bmi &lt;- sd(diabetes_data_clean$BMI, na.rm = TRUE)\n\n# Define the boundaries for 3 standard deviations from the mean\nlower_bound &lt;- mean_bmi - 3 * sd_bmi\nupper_bound &lt;- mean_bmi + 3 * sd_bmi\n\n# Plot with faceting\nggplot(combined_data, aes(x = BMI)) +\n  geom_histogram(binwidth = 1, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = c(lower_bound, upper_bound), color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Histogram of BMI\", x = \"BMI\", y = \"Frequency\") +\n  facet_wrap(~ Source) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIn a typical Quantile-Quantile (QQ) plot, we expect to see a diagonal, mostly straight line. However, in the case of BMI without removal of outliers, the Q-Q plot shows a significant deviation from this pattern. The tails of the Q-Q line curve away from the diagonal line quite drastically, which strongly indicates the presence of outliers.\n\n\n# Combine the datasets\ncombined_data &lt;- bind_rows(\n  mutate(diabetes_data_clean, Source = \"With Outliers\"),\n  mutate(diabetes_data_clean_noOutliers, Source = \"No Outliers\")\n)\n\n# Plot with faceting\nggplot(combined_data, aes(sample = BMI)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  labs(title = \"QQ Plot of BMI\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  facet_wrap(~ Source) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nBased on the totality of the information, I decided to treat BMI values of 50 and higher as outliers and remove them from the dataset. I chose a conservative approach using the Z-score method, which set the cutoff at 49. In contrast, the IQR and boxplot methods suggested a cutoff at 42, resulting in the removal of 6,000 more observations than the Z-score method. Given the dataset’s large size, I wanted to avoid being overly aggressive without consulting a health specialist or someone familiar with the data collection. After rerunning the boxplot, histogram, and QQ plot, I am confident in moving forward with the dataset after removing the outliers.\n\n\n\nData Summary\nAs a result of there being many variables, grouping the factored variables into themes made sense.\n\n\n# Group variables into common themes.\nHealth_Factors &lt;- c(\"Diabetes_binary\",\"HighBP\",\"HighChol\",\"Stroke\",\"HeartDiseaseorAttack\",\"DiffWalk\",\"Sex\")\nLifestyle_Factors &lt;- c(\"PhysActivity\",\"Smoker\",\"Fruits\",\"Veggies\",\"HvyAlcoholConsump\")\nHealthcare_Factors &lt;- c(\"CholCheck\",\"AnyHealthcare\",\"NoDocbcCost\")\n\n\n\n\n\n\n\n\nHealth Factors\nLevels\nCounts\nProportions\n\n\n\n\nDiabetes_binary\n0,1\n216638(0) 34495(1)\n0.86(0) 0.14(1)\n\n\nHighBP\n0,1\n143908(0) 107225(1)\n0.57(0) 0.43(1)\n\n\nHighChol\n0,1\n144693(0) 106440(1)\n0.58(0) 0.42(1)\n\n\nStroke\n0,1\n240973(0) 10160(1)\n0.96(0) 0.04(1)\n\n\nHeartDiseaseorAttack\n0,1\n227533(0) 23600(1)\n0.91(0) 0.09(1)\n\n\nDiffWalk\n0,1\n209752(0) 41381(1)\n0.84(0) 0.16(1)\n\n\nSex\n0,1\n140299(0) 110834(1)\n0.56(0) 0.44(1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLifestyle Factors\nLevels\nCounts\nProportions\n\n\n\n\nPhysActivity\n0,1\n60557(0) 190576(1)\n0.24(0) 0.76(1)\n\n\nSmoker\n0,1\n139778(0) 111355(1)\n0.56(0) 0.44(1)\n\n\nFruits\n0,1\n91567(0) 159566(1)\n0.36(0) 0.64(1)\n\n\nVeggies\n0,1\n47198(0) 203935(1)\n0.19(0) 0.81(1)\n\n\nHvyAlcoholConsump\n0,1\n236945(0) 14188(1)\n0.94(0) 0.06(1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHealthcare Factors\nLevels\nCounts\nProportions\n\n\n\n\nCholCheck\n0,1\n9398(0) 241735(1)\n0.04(0) 0.96(1)\n\n\nAnyHealthcare\n0,1\n12218(0) 238915(1)\n0.05(0) 0.95(1)\n\n\nNoDocbcCost\n0,1\n230169(0) 20964(1)\n0.92(0) 0.08(1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Statistics on Non-Factor Variables\n\n\n\n\nMin\n1st Qu.\nMedian\nMean\n3rd Qu.\nMax\n\n\n\n\nBMI\n12\n24\n27\n28.057372\n31\n49\n\n\nGenHlth\n1\n2\n2\n2.503227\n3\n5\n\n\nAge\n1\n6\n8\n8.043053\n10\n13\n\n\nEducation\n1\n4\n5\n5.053008\n6\n6\n\n\nIncome\n1\n5\n7\n6.064874\n8\n8\n\n\nMentHlth\n0\n0\n0\n3.151000\n2\n30\n\n\nPhysHlth\n0\n0\n0\n4.186328\n3\n30\n\n\n\n\n\n\n\n\n\n\n\nData Visualization\n\n# Define the red and gray colors\nncsu_colors &lt;- c(\n  \"0\" = \"#5B6770\",  # Gray for absence\n  \"1\" = \"#CC0000\"   # Red for presence\n)\n\n# Define health factors excluding Diabetes_binary\nHealth_Factors &lt;- c(\"HighBP\", \"HighChol\", \"Stroke\", \"HeartDiseaseorAttack\", \"DiffWalk\")\n\n# Filter dataset for Diabetes_binary = 1\nfiltered_data &lt;- diabetes_data_clean_noOutliers %&gt;%\n  filter(Diabetes_binary == 1) %&gt;%\n  select(all_of(Health_Factors))\n\n# Convert data to long format\nlong_data &lt;- filtered_data %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Health_Factor\", values_to = \"Value\") %&gt;%\n  group_by(Health_Factor, Value) %&gt;%\n  summarize(Count = n(), .groups = \"drop\")\n\n# Create the stacked horizontal bar chart with custom red and gray colors\nggplot(long_data, aes(x = Count, y = Health_Factor, fill = as.factor(Value))) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(\n    values = ncsu_colors,\n    labels = c(\"0\" = \"Absence\", \"1\" = \"Presence\")  # Change legend labels\n  ) +\n  labs(\n    x = \"Count\",\n    y = \"Health Factor\",\n    fill = \"Level\",\n    title = \"Health Factors for those diagnosed with Diabetes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe bar chart reveals that a positive diabetes diagnosis is indiscriminate along gender lines, indicating that both males and females are equally likely to be diagnosed with diabetes. This suggests that gender does not play a significant role in the prevalence of diabetes within the studied population.\nInterestingly, the presence of heart disease, including at least one heart attack or stroke, does not appear to be a necessary comorbidity for diabetes. While cardiovascular issues are common among diabetes patients, their absence in a substantial number of cases indicates that diabetes can develop independently of these conditions.\nHowever, the data shows that high cholesterol and high blood pressure are prevalent among diabetes patients, with over two-thirds of those diagnosed exhibiting these conditions. This finding underscores the strong association between diabetes and these two risk factors. High cholesterol and high blood pressure are known to contribute to insulin resistance and other metabolic disturbances that can lead to the development and progression of diabetes.\nThis information is crucial for both preventive measures and management strategies. For instance, monitoring and controlling blood pressure and cholesterol levels should be a priority in diabetes prevention programs. For individuals already diagnosed with diabetes, managing these conditions is essential to prevent complications and improve overall health outcomes.\n\n# Define the red and gray colors\nncsu_colors &lt;- c(\n  \"0\" = \"#5B6770\",  # Gray for absence\n  \"1\" = \"#CC0000\"   # Red for presence\n)\n\n# Define lifestyle factors\nLifestyle_Factors &lt;- c(\"PhysActivity\", \"Smoker\", \"Fruits\", \"Veggies\", \"HvyAlcoholConsump\")\n\n# Filter dataset for Diabetes_binary = 1\nfiltered_data_lifestyle &lt;- diabetes_data_clean_noOutliers %&gt;%\n  filter(Diabetes_binary == 1) %&gt;%\n  select(all_of(Lifestyle_Factors))\n\n# Convert all columns to factors\nfiltered_data_lifestyle &lt;- filtered_data_lifestyle %&gt;%\n  mutate(across(everything(), as.factor))\n\n# Convert data to long format\nlong_data_lifestyle &lt;- filtered_data_lifestyle %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Lifestyle_Factor\", values_to = \"Value\") %&gt;%\n  group_by(Lifestyle_Factor, Value) %&gt;%\n  summarize(Count = n(), .groups = \"drop\")\n\n# Create the stacked horizontal bar chart with custom ncsu colors\nggplot(long_data_lifestyle, aes(x = Count, y = Lifestyle_Factor, fill = as.factor(Value))) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(\n    values = ncsu_colors,\n    labels = c(\"0\" = \"Absence\", \"1\" = \"Presence\")  # Change legend labels\n  ) +\n  labs(\n    x = \"Count\",\n    y = \"Lifestyle Factor\",\n    fill = \"Level\",\n    title = \"Lifestyle Factors for those diagnosed with Diabetes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nMany of the variables in the lifestyle group—such as smoking, physical activity, and fruit consumption—are split evenly among the participants. However, a noteworthy finding is that heavy alcohol consumption is not common among patients diagnosed with diabetes. In contrast, over three-quarters of these patients reported consuming vegetables one or more times a day.\nThis disparity between fruit and vegetable consumption is intriguing. I hypothesize that it may be due to the different ways these foods are typically prepared and consumed. Fruits are often eaten raw, making them convenient and quick to consume without additional preparation. On the other hand, vegetables frequently require cooking or seasoning, which may involve adding ingredients like oils, sauces, or salt. This additional preparation might affect the frequency and ease with which vegetables are consumed compared to fruits.\nFurthermore, it’s worth exploring how these dietary habits correlate with diabetes management and overall health outcomes. For instance, the nutrients obtained from raw fruits and prepared vegetables might have different impacts on blood sugar levels and other health markers. Understanding these nuances can help tailor dietary recommendations more effectively for individuals with diabetes.\n\n# Define the red and gray colors\nncsu_colors &lt;- c(\n  \"0\" = \"#5B6770\",  # Gray for absence\n  \"1\" = \"#CC0000\"   # Red for presence\n)\n\n# Define healthcare factors\nHealthcare_Factors &lt;- c(\"CholCheck\", \"AnyHealthcare\", \"NoDocbcCost\")\n\n# Filter dataset for Diabetes_binary = 1\nfiltered_data_healthcare &lt;- diabetes_data_clean_noOutliers %&gt;%\n  filter(Diabetes_binary == 1) %&gt;%\n  select(all_of(Healthcare_Factors))\n\n# Convert data to long format\nlong_data_healthcare &lt;- filtered_data_healthcare %&gt;%\n  pivot_longer(cols = everything(), names_to = \"Healthcare_Factor\", values_to = \"Value\") %&gt;%\n  group_by(Healthcare_Factor, Value) %&gt;%\n  summarize(Count = n(), .groups = \"drop\")\n\n# Create the stacked horizontal bar chart with custom ncsu colors\nggplot(long_data_healthcare, aes(x = Count, y = Healthcare_Factor, fill = as.factor(Value))) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(\n    values = ncsu_colors,\n    labels = c(\"0\" = \"Absence\", \"1\" = \"Presence\")  # Change legend labels\n  ) +\n  labs(\n    x = \"Count\",\n    y = \"Healthcare Factor\",\n    fill = \"Level\",\n    title = \"Healthcare Factors for those diagnosed with Diabetes\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHealthcare factors significantly influence the diagnosis of diabetes. Approximately 97% of participants reported having had a cholesterol check within the last five years, and around 95% confirmed having healthcare coverage. It stands to reason that both a cholesterol check and healthcare coverage are essential for diagnosing diabetes. Furthermore, these two variables might interact with each other, so we will test for their covariance.\nEight percent of patients reported not seeing a doctor when needed in the past 12 months due to cost. While the United States has made significant strides in expanding healthcare coverage, this remaining proportion highlights the need for further adjustments in public policy to ensure that all individuals can access medical care regardless of expense.\n\n# Define the NCSU colors\nncsu_colors &lt;- c(\n  \"Distribution\" = \"#CC0000\",  # Red for the distribution\n  \"Mean\" = \"#0000FF\",         # Blue for the mean line\n  \"Median\" = \"#FFA500\"        # Orange for the median line\n)\n\n# Create the plot\nggplot(diabetes_data_clean_noOutliers, aes(x = BMI)) +\n  geom_histogram(\n    binwidth = 1,  # Adjust binwidth as needed\n    fill = ncsu_colors[\"Distribution\"],\n    color = \"black\",\n    alpha = 0.7\n  ) +\n  geom_vline(aes(xintercept = mean(BMI, na.rm = TRUE)), color = ncsu_colors[\"Mean\"], linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = median(BMI, na.rm = TRUE)), color = ncsu_colors[\"Median\"], linetype = \"dotted\", size = 1) +\n  annotate(\"text\", x = mean_bmi, y = Inf, label = \"Mean\", color = ncsu_colors[\"Mean\"], vjust = 1.5, hjust = 1.1) +\n  \n \n  labs(\n    title = \"Distribution of BMI\",\n    x = \"BMI\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe have already examined the histogram after removing the outliers, but I wanted to present a more detailed view to highlight some nuances. Upon removing the outliers, we first observe that the right tail tapers but then abruptly gets truncated at around 500 observations when values reach 49. There is still a slight right skew, as the mean is positioned to the right of the median, indicating that the distribution of observations is not perfectly symmetrical around the mean..\n\n\n\n\n\n\n\n\n\nThis facet contains plots from diagnosed diabetics based on our non-factor variables. Patients were observed to report their general health as good, fair, or poor, indicating a decline in quality of life. Regarding education, diabetes diagnoses were evenly distributed among high school graduates, college graduates, and those with any college or technical school experience. Diabetes appears to be more prevalent among higher-income and older individuals, suggesting a possible interaction between these two variables that warrants further investigation. Many diabetics reported no days of mental or physical health issues, though more individuals with diabetes reported a higher number of days with physical health issues compared to mental health issues.\n\n\n\n\n\n\n\n\n\n\nMore Americans without diabetes reported their health as excellent, very good, or good. While the number of individuals without a diabetes diagnosis significantly exceeds those with a diagnosis, the proportion of people reporting fair or poor health among non-diabetics was nearly double that of diabetics. This suggests that even among non-diabetics, there is a substantial subset experiencing poor health.\n\nEducation levels were less uniform among non-diabetics compared to diabetics. The distributions of income and age among non-diabetics closely mirror those of diabetics, though the absolute number of observations differs. This indicates that age and income are similarly distributed across both groups, despite the difference in sample size.\n\nThe Mental Health and Physical Health variables showed similar patterns between diabetics and non-diabetics. Many individuals in both groups reported no days of mental or physical health issues, although the overall number of days with health issues was comparable. This highlights that while diabetes may exacerbate health problems, the general population also experiences significant health challenges.\n\n\nAppendix: Variable description\n(Disease Control & Prevention, 2015)\nDiabetes_binary\nNOTE: The options present are different from the source data.\n0 = no diabetes/prediabetes\n1 = diabetes\n\nHighBP\n0 = no high BP\n1 = high BP\n\nHighChol\n0 = no high cholesterol\n1 = high cholesterol\n\nCholCheck\n0 = no cholesterol check in 5 years\n1 = cholesterol check in 5 years\n\nBMI\nContinuous Data\n\nSmoker\nTo the question: Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes]\n0 = no\n1 = yes\n\nStroke\nTo the question: (Ever told) you had a stroke.\n0 = no\n1 = yes\n\nHeartDiseaseorAttack\nCoronary heart disease (CHD) or myocardial infarction (MI)\n0 = no\n1 = yes\n\nPhysActivity\nPhysical activity in past 30 days (not including job)\n0 = no\n1 = yes\n\nFruits\nConsume Fruit 1 or more times per day\n0 = no\n1 = yes\n\nVeggies\nConsume Vegetables 1 or more times per day\n0 = no\n1 = yes\n\nHvyAlcoholConsump\n(adult men &gt;=14 drinks per week and adult women&gt;=7 drinks per week)\n0 = no\n1 = yes\n\nAnyHealthcare\nHave any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc.\n0 = no\n1 = yes\n\nNoDocbcCost\nTo the question: Was there a time in the past 12 months when you needed to see a doctor but could not because of cost?\n0 = no\n1 = yes\n\nGenHlth\nTo the question: Would you say that in general your health is: scale 1-5\n1 = excellent\n2 = very good\n3 = good\n4 = fair\n5 = poor\n\nMentHlth\nDays of poor mental health scale 1-30 days\n\nPhysHlth\nphysical illness or injury days in past 30 days scale 1-30\n\nDiffWalk\nDo you have serious difficulty walking or climbing stairs?\n0 = no\n1 = yes\n\nSex\n0 = female\n1 = male\n\nAge\nNOTE: The options present are different from the source data.\n1 = Age 18 to 24 Respondents with reported age between 18 and 24 years (18 &lt;= AGE &lt;= 24)\n2 = Age 25 to 29 Respondents with reported age between 25 and 29 years (25 &lt;= AGE &lt;= 29)\n3 = Age 30 to 34 Respondents with reported age between 30 and 34 years (30 &lt;= AGE &lt;= 34)\n4 = Age 35 to 39 Respondents with reported age between 35 and 39 years (35 &lt;= AGE &lt;= 39)\n5 = Age 40 to 44 Respondents with reported age between 40 and 44 years (40 &lt;= AGE &lt;= 44)\n6 = Age 45 to 49 Respondents with reported age between 45 and 49 years (45 &lt;= AGE &lt;= 49)\n7 = Age 50 to 54 Respondents with reported age between 50 and 54 years (50 &lt;= AGE &lt;= 54)\n8 = Age 55 to 59 Respondents with reported age between 55 and 59 years (55 &lt;= AGE &lt;= 59)\n9 = Age 60 to 64 Respondents with reported age between 60 and 64 years (60 &lt;= AGE &lt;= 64)\n10 = Age 65 to 69 Respondents with reported age between 65 and 69 years (65 &lt;= AGE &lt;= 69)\n11 = Age 70 to 74 Respondents with reported age between 70 and 74 years (70 &lt;= AGE &lt;= 74)\n12 = Age 75 to 79 Respondents with reported age between 75 and 79 years (75 &lt;= AGE &lt;= 79)\n13 = Age 80 or older Respondents with reported age between 80 and 99 years (80 &lt;= AGE &lt;= 99)\n\nEducation\nNOTE: The options present are different from the source data.\n1 = Never attended school or only kindergarten\n2 = Grades 1 through 8 (Elementary)\n3 = Grades 9 through 11 (Some high school)\n4 = Grade 12 or GED (High school graduate)\n5 = College 1 year to 3 years (Some college or technical school)\n6 = College 4 years or more (College graduate)\n\nIncome\nNOTE: The options present are different from the source data.\n1 = Less than $10,000\n2 = Less than $15,000 ($10,000 to less than $15,000)\n3 = Less than $20,000 ($15,000 to less than $20,000)\n4 = Less than $25,000 ($20,000 to less than $25,000)\n5 = Less than $35,000 ($25,000 to less than $35,000)\n6 = Less than $50,000 ($35,000 to less than $50,000)\n7 = Less than $75,000 ($50,000 to less than $75,000)\n8 = $75,000 or more\n\nLink to Modeling.qmd on Github\n\n\n\n\n\n\n\n\n\nReferences\n\nDisease Control, C. for, & Prevention. (2015). BRFSS codebook 2015. https://www.cdc.gov/brfss/annual_data/2015/pdf/codebook15_llcp.pdf"
  }
]